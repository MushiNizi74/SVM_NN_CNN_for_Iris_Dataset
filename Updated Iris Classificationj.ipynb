{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "b94352ed", "cell_type": "markdown", "source": "# Iris Classification Refactored\nThis notebook is a rewritten, clean version of the original script.", "metadata": {}}, {"id": "cd271afc", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n\"\"\"\niris_classification_refactor.py\n\nPurpose:\n  - Load Iris features & labels from NumPy files\n  - Explore basic dataset statistics\n  - Standardize features\n  - Build, train and evaluate a small neural classifier using TensorFlow/Keras\n  - Plot training curves and simple 2D scatter visualizations\n\nNotes:\n  - Make sure 'Iris_data.npy' and 'Iris_labels.npy' are in the same directory\n  - Tested with: Python 3.8+, tensorflow 2.x, scikit-learn, matplotlib, numpy\n\"\"\"\n\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom typing import Tuple\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntf.random.set_seed(RANDOM_SEED)\n\n\ndef load_data(features_path: str = \"Iris_data.npy\",\n              labels_path: str = \"Iris_labels.npy\") -> Tuple[np.ndarray, np.ndarray]:\n    if not (os.path.exists(features_path) and os.path.exists(labels_path)):\n        raise FileNotFoundError(\"Make sure Iris_data.npy and Iris_labels.npy exist in the working directory.\")\n    X = np.load(features_path)\n    y = np.load(labels_path)\n    return X, y\n\n\ndef quick_stats(X: np.ndarray, y: np.ndarray) -> None:\n    n_samples, n_features = X.shape\n    n_classes = len(np.unique(y))\n    print(f\"Samples: {n_samples}, Features: {n_features}, Classes: {n_classes}\")\n    print(f\"Feature means: {np.round(X.mean(axis=0), 3)}\")\n    print(f\"Feature std devs: {np.round(X.std(axis=0), 3)}\")\n    print(f\"Labels distribution: {dict(zip(*np.unique(y, return_counts=True)))}\")\n\n\ndef plot_raw_data(X: np.ndarray, y: np.ndarray) -> None:\n    plt.figure(figsize=(6, 5))\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"viridis\", edgecolor=\"k\", s=50)\n    plt.xlabel(\"Feature 0\")\n    plt.ylabel(\"Feature 1\")\n    plt.title(\"Raw data (first two feature dims)\")\n    plt.grid(alpha=0.3)\n    plt.show()\n\n\ndef prepare_data(X: np.ndarray, y: np.ndarray, test_size: float = 0.2):\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=test_size, random_state=RANDOM_SEED, stratify=y\n    )\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n\n\ndef build_model(input_dim: int, num_classes: int) -> tf.keras.Model:\n    model = tf.keras.Sequential([\n        tf.keras.layers.InputLayer(input_shape=(input_dim,)),\n        tf.keras.layers.Dense(64, activation=\"relu\"),\n        tf.keras.layers.Dense(32, activation=\"relu\"),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n    ], name=\"Iris_Classifier\")\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    return model\n\n\ndef plot_training(history: tf.keras.callbacks.History) -> None:\n    hist = history.history\n    epochs = range(1, len(hist[\"loss\"]) + 1)\n\n    plt.figure(figsize=(12, 4))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, hist[\"loss\"], label=\"train_loss\")\n    if \"val_loss\" in hist:\n        plt.plot(epochs, hist[\"val_loss\"], label=\"val_loss\")\n    plt.title(\"Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.legend()\n    plt.grid(alpha=0.3)\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, hist[\"accuracy\"], label=\"train_acc\")\n    if \"val_accuracy\" in hist:\n        plt.plot(epochs, hist[\"val_accuracy\"], label=\"val_acc\")\n    plt.title(\"Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.legend()\n    plt.grid(alpha=0.3)\n\n    plt.show()\n\n\ndef visualize_predictions(model: tf.keras.Model, X_test: np.ndarray, y_test: np.ndarray, scaler: StandardScaler = None) -> None:\n    preds = np.argmax(model.predict(X_test), axis=1)\n\n    plt.figure(figsize=(6, 5))\n    plt.scatter(X_test[:, 0], X_test[:, 1], c=preds, cmap=\"plasma\", s=60, marker=\"o\", edgecolor=\"k\", alpha=0.9)\n    plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=\"cool\", s=12, marker=\"x\")\n    plt.title(\"Test data: large markers = predicted class, small x = true class\")\n    plt.xlabel(\"Feature 0 (scaled)\")\n    plt.ylabel(\"Feature 1 (scaled)\")\n    plt.grid(alpha=0.25)\n    plt.show()\n\n\ndef main():\n    X, y = load_data(\"Iris_data.npy\", \"Iris_labels.npy\")\n    quick_stats(X, y)\n    plot_raw_data(X, y)\n    X_tr, X_te, y_tr, y_te, scaler = prepare_data(X, y, test_size=0.2)\n    print(f\"Train / Test sizes: {X_tr.shape[0]} / {X_te.shape[0]}\")\n    model = build_model(input_dim=X_tr.shape[1], num_classes=len(np.unique(y)))\n    model.summary()\n    history = model.fit(\n        X_tr, y_tr,\n        validation_split=0.15,\n        epochs=40,\n        batch_size=16,\n        verbose=1\n    )\n    plot_training(history)\n    loss, acc = model.evaluate(X_te, y_te, verbose=0)\n    print(f\"Test loss: {loss:.4f}  |  Test accuracy: {acc*100:.2f}%\")\n    visualize_predictions(model, X_te, y_te, scaler=scaler)\n\n\nif __name__ == \"__main__\":\n    main()\n", "outputs": []}]}